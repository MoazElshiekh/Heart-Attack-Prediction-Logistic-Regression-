# Heart Attack Prediction Dataset Analysis

## Step 1: Data Loading, Inspection, and Cleaning

### Dataset Overview
The dataset contains information about various health and lifestyle factors that may contribute to the risk of heart attacks. The dataset includes 8,763 entries and 26 columns, with data points such as age, cholesterol levels, blood pressure, diabetes status, and more.

### Dataset Columns
The dataset includes the following columns:
1. `Patient ID` - Unique identifier for each patient
2. `Age` - Age of the patient
3. `Sex` - Gender of the patient
4. `Cholesterol` - Cholesterol level
5. `Blood Pressure` - Blood pressure reading
6. `Heart Rate` - Heart rate in beats per minute
7. `Diabetes` - Diabetes status (binary)
8. `Family History` - Family history of heart disease (binary)
9. `Smoking` - Smoking status (binary)
10. `Obesity` - Obesity status (binary)
11. `Alcohol Consumption` - Frequency of alcohol consumption
12. `Exercise Hours Per Week` - Hours of exercise per week
13. `Diet` - Diet quality
14. `Previous Heart Problems` - History of heart problems (binary)
15. `Medication Use` - Medication usage (binary)
16. `Stress Level` - Stress level
17. `Sedentary Hours Per Day` - Hours spent sedentary per day
18. `Income` - Annual income
19. `BMI` - Body Mass Index
20. `Triglycerides` - Triglyceride levels
21. `Physical Activity Days Per Week` - Days of physical activity per week
22. `Sleep Hours Per Day` - Hours of sleep per day
23. `Country` - Country of residence
24. `Continent` - Continent of residence
25. `Hemisphere` - Hemisphere of residence
26. `Heart Attack Risk` - Risk of heart attack (binary)

### Loading the Dataset
The dataset is loaded into a pandas DataFrame using the `pd.read_csv` function. The file path to the dataset is provided as `~/Downloads/heart_attack_prediction_dataset.csv`.

```python
import pandas as pd

# Load the dataset
file_path = "~/Downloads/heart_attack_prediction_dataset.csv"
df = pd.read_csv(file_path)
```

### Initial Inspection
Basic information about the dataset is displayed, including its shape, data types, and the first few rows of the dataset.

```python
# Display basic information about the dataset
print("Dataset Shape:", df.shape)
print("\nDataset Info:")
print(df.info())
print("\nDataset Head:")
print(df.head())
```

### Missing Values
The dataset is checked for missing values. In this case, no missing values are found.

```python
# Check for missing values
print("\nMissing Values:")
print(df.isnull().sum())
```

### Duplicate Rows
The dataset is checked for duplicate rows. No duplicate rows are found in the dataset.

```python
# Check for duplicates
print("\nDuplicate Rows:")
print(df.duplicated().sum())
```

### Handling Missing Values
For demonstration purposes, any rows with missing values are dropped. However, since no missing values were found, this step does not alter the dataset in this case.

```python
# Handle missing values
# For demonstration purposes, let's drop rows with missing values
df.dropna(inplace=True)
```

### Summary
- The dataset is successfully loaded and inspected.
- There are 8,763 entries and 26 columns.
- No missing values or duplicate rows are present in the dataset.
- The dataset is ready for further analysis and processing.

---

This section sets up the initial exploration and cleaning of the dataset, ensuring it is ready for further analysis.
